{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket_S6T3_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S6T3_post.mp4\n",
      "basket_S6T4_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S6T4_post.mp4\n",
      "basket_S6T5_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S6T5_post.mp4\n",
      "basket_S6T6_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S6T6_post.mp4\n",
      "basket_S6T7_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S6T7_post.mp4\n",
      "basket_S1T1_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S1T1_pre.mp4\n",
      "basket_S1T2_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S1T2_pre.mp4\n",
      "basket_S1T3_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S1T3_pre.mp4\n",
      "basket_S1T4_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S1T4_pre.mp4\n",
      "basket_S1T5_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S1T5_pre.mp4\n",
      "basket_S1T6_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S1T6_pre.mp4\n",
      "basket_S1T7_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S1T7_pre.mp4\n",
      "basket_S2T1_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S2T1_pre.mp4\n",
      "basket_S2T2_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S2T2_pre.mp4\n",
      "basket_S2T3_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S2T3_pre.mp4\n",
      "basket_S2T4_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S2T4_pre.mp4\n",
      "basket_S2T5_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S2T5_pre.mp4\n",
      "basket_S2T6_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S2T6_pre.mp4\n",
      "basket_S2T7_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S2T7_pre.mp4\n",
      "basket_S3T1_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S3T1_pre.mp4\n",
      "basket_S3T2_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S3T2_pre.mp4\n",
      "basket_S3T3_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S3T3_pre.mp4\n",
      "basket_S3T4_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S3T4_pre.mp4\n",
      "basket_S3T5_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S3T5_pre.mp4\n",
      "basket_S3T6_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S3T6_pre.mp4\n",
      "basket_S3T7_pre.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S3T7_pre.mp4\n",
      "basket_S4T1_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S4T1_post.mp4\n",
      "basket_S4T2_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S4T2_post.mp4\n",
      "basket_S4T3_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S4T3_post.mp4\n",
      "basket_S4T4_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S4T4_post.mp4\n",
      "basket_S4T5_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S4T5_post.mp4\n",
      "basket_S4T6_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S4T6_post.mp4\n",
      "basket_S4T7_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S4T7_post.mp4\n",
      "basket_S5T1_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S5T1_post.mp4\n",
      "basket_S5T2_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S5T2_post.mp4\n",
      "basket_S5T3_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S5T3_post.mp4\n",
      "basket_S5T4_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S5T4_post.mp4\n",
      "basket_S5T5_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S5T5_post.mp4\n",
      "basket_S5T6_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S5T6_post.mp4\n",
      "basket_S5T7_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S5T7_post.mp4\n",
      "basket_S6T1_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S6T1_post.mp4\n",
      "basket_S6T2_post.mp4 の処理完了。出力: ../videos/Indoor/minimap_drawn/basket_S6T2_post.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# --- Directories ---\n",
    "input_video_dir = \"../../videos/Indoor/\"\n",
    "mot_dir = \"../../BoT-SORT_outputs/Indoor/filtered/merged/\"\n",
    "att_dir = \"../../BoT-SORT_outputs/Indoor/transformed/merged_with_attributes/\"\n",
    "color_dir = \"../../ground_truth/Indoor/transformed_MOT\"\n",
    "output_dir = \"../../videos/Indoor/minimap_drawn\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Video directory for minimap\n",
    "pred_dir = \"../../videos/Indoor/minimap/prediction\"\n",
    "gt_dir   = \"../../videos/Indoor/minimap/ground_truth\"\n",
    "\n",
    "# Color conversion mapping for MOT（lowercase）\n",
    "mot_color_map = {\n",
    "    \"red\": (0, 0, 204),\n",
    "    \"blue\": (204, 0, 0),\n",
    "    \"pink\": (144, 84, 204),\n",
    "    \"black\": (0, 0, 0),\n",
    "    \"orange\": (0, 120, 204),\n",
    "    \"yellow\": (108, 204, 176),  # yellowはgreenとして解釈\n",
    "}\n",
    "\n",
    "# --- File read function ---\n",
    "def load_mot_file(path):\n",
    "    mot_dict = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = [p.strip() for p in line.split(\",\")]\n",
    "            if len(parts) < 6:\n",
    "                continue\n",
    "            try:\n",
    "                frame = int(float(parts[0]))  \n",
    "                track_id = int(float(parts[1]))\n",
    "                x = float(parts[2])\n",
    "                y = float(parts[3])\n",
    "                w = float(parts[4])\n",
    "                h = float(parts[5])\n",
    "            except Exception as e:\n",
    "                print(f\"parse error: {line}\")\n",
    "                continue\n",
    "            if frame not in mot_dict:\n",
    "                mot_dict[frame] = {}\n",
    "            mot_dict[frame][track_id] = (x, y, w, h)\n",
    "    return mot_dict\n",
    "\n",
    "def load_att_file(path):\n",
    "    att_dict = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = [p.strip() for p in line.split(\",\")]\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            try:\n",
    "                frame = int(float(parts[0]))  \n",
    "                track_id = int(float(parts[1]))\n",
    "                x = float(parts[2])\n",
    "                y = float(parts[3])\n",
    "                attribute = parts[-1]\n",
    "            except Exception as e:\n",
    "                print(f\"Attribute file parsing error: {line}\")\n",
    "                continue\n",
    "            if frame not in att_dict:\n",
    "                att_dict[frame] = {}\n",
    "            att_dict[frame][track_id] = (x, y, attribute)\n",
    "    return att_dict\n",
    "\n",
    "def load_color_file(path):\n",
    "    color_dict = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = [p.strip() for p in line.split(\",\")]\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            try:\n",
    "                frame = int(float(parts[0]))  \n",
    "                track_id = int(float(parts[1]))\n",
    "                x = float(parts[2])\n",
    "                y = float(parts[3])\n",
    "                color_str = parts[4].lower()\n",
    "            except Exception as e:\n",
    "                print(f\"Color file parsing error: {line}\")\n",
    "                continue\n",
    "            if frame not in color_dict:\n",
    "                color_dict[frame] = {}\n",
    "            color_dict[frame][track_id] = (x, y, color_str)\n",
    "    return color_dict\n",
    "\n",
    "def build_track_color_mapping(att_data, color_data):\n",
    "    mapping = {}\n",
    "    att_frame = 1\n",
    "    color_frame = 1\n",
    "    if att_frame not in att_data or color_frame not in color_data:\n",
    "        print(\"Data for the first frame is missing.\")\n",
    "        return mapping\n",
    "    att_tracks = att_data[att_frame]\n",
    "    color_tracks = color_data[color_frame]\n",
    "    for att_tid, (ax, ay, _) in att_tracks.items():\n",
    "        min_dist = float(\"inf\")\n",
    "        matched_color = None\n",
    "        for color_tid, (cx, cy, color_str) in color_tracks.items():\n",
    "            dist = math.hypot(ax - cx, ay - cy)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                matched_color = color_str\n",
    "        if matched_color is not None:\n",
    "            mapping[att_tid] = mot_color_map.get(matched_color, (0, 0, 0))\n",
    "    return mapping\n",
    "\n",
    "# --- Each video processing loop ---\n",
    "for video_file in os.listdir(input_video_dir):\n",
    "    if not video_file.endswith(\".mp4\"):\n",
    "        continue\n",
    "\n",
    "    video_path = os.path.join(input_video_dir, video_file)\n",
    "    mot_path = os.path.join(mot_dir, os.path.splitext(video_file)[0] + \".txt\")\n",
    "    att_path = os.path.join(att_dir, os.path.splitext(video_file)[0] + \".txt\")\n",
    "    color_path = os.path.join(color_dir, os.path.splitext(video_file)[0] + \"_color.txt\")\n",
    "    \n",
    "    pred_video_path = os.path.join(pred_dir, video_file)\n",
    "    gt_video_path   = os.path.join(gt_dir, video_file)\n",
    "    \n",
    "    if not os.path.exists(mot_path):\n",
    "        print(f\"MOT file not found: {mot_path}\")\n",
    "        continue\n",
    "    if not os.path.exists(att_path):\n",
    "        print(f\"Attribute file not found: {att_path}\")\n",
    "        continue\n",
    "    if not os.path.exists(color_path):\n",
    "        print(f\"Color file not found: {color_path}\")\n",
    "        continue\n",
    "    if not os.path.exists(pred_video_path):\n",
    "        print(f\"Prediction video not found: {pred_video_path}\")\n",
    "        continue\n",
    "    if not os.path.exists(gt_video_path):\n",
    "        print(f\"Ground Truth video not found: {gt_video_path}\")\n",
    "        continue\n",
    "\n",
    "    mot_data = load_mot_file(mot_path)      \n",
    "    att_data = load_att_file(att_path)        \n",
    "    color_data = load_color_file(color_path)  \n",
    "    track_color_mapping = build_track_color_mapping(att_data, color_data)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    pred_cap = cv2.VideoCapture(pred_video_path)\n",
    "    gt_cap = cv2.VideoCapture(gt_video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Could not open video: {video_path}\")\n",
    "        continue\n",
    "\n",
    "    main_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    main_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    output_video_path = os.path.join(output_dir, video_file)\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (main_width, main_height))\n",
    "    \n",
    "    # Set M to 1/5 of the width of the main video\n",
    "    M = main_width / 5.0\n",
    "    L = (4/3.0) * M\n",
    "    \n",
    "    # Resize the mini-map video to width M, keeping the original aspect ratio\n",
    "    # First, get the original size from one frame of the Prediction video\n",
    "    ret_pred, first_pred = pred_cap.read()\n",
    "    if not ret_pred:\n",
    "        print(f\"Failure to acquire frames for Prediction video: {pred_video_path}\")\n",
    "        continue\n",
    "    orig_pred_h, orig_pred_w = first_pred.shape[:2]\n",
    "    # Aspect ratio r = h / w, thus height after resizing H = M * r\n",
    "    r = orig_pred_h / orig_pred_w\n",
    "    H = M * r\n",
    "    # reset\n",
    "    pred_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    gt_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    comp_width = (7/3.0) * M\n",
    "    pred_x = int(L)\n",
    "    gt_x = int(L + M + (M/3.0))\n",
    "\n",
    "    label_space = 30\n",
    "    overlay_y = main_height - int(H + label_space)\n",
    "    \n",
    "    # --- Font settings for labels ---\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1\n",
    "    font_thickness = 2\n",
    "    label_color = (0, 0, 0)  # black\n",
    "\n",
    "    frame_index = 0\n",
    "    while True:\n",
    "        ret_main, main_frame = cap.read()\n",
    "        if not ret_main:\n",
    "            break\n",
    "\n",
    "        current_mot_frame = frame_index         \n",
    "        current_att_frame = frame_index + 1       \n",
    "        if current_mot_frame in mot_data:\n",
    "            for track_id, bbox in mot_data[current_mot_frame].items():\n",
    "                x, y, w, h = bbox\n",
    "                a = w / 2\n",
    "                b = a / 5\n",
    "                cx = int(x + w/2)\n",
    "                cy = int(y + h + b/2)\n",
    "                color = track_color_mapping.get(track_id, (0, 0, 0))\n",
    "                cv2.ellipse(main_frame, (cx, cy), (int(a), int(b)), 0, 330, 570, color, 2)\n",
    "                attribute = \"\"\n",
    "                if current_att_frame in att_data and track_id in att_data[current_att_frame]:\n",
    "                    attribute = att_data[current_att_frame][track_id][2]\n",
    "                text_pos = (int(x), int(y - 10))\n",
    "                cv2.putText(main_frame, attribute, text_pos,\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)\n",
    "        \n",
    "        # --- mini-map overlay ---\n",
    "        ret_pred, frame_pred = pred_cap.read()\n",
    "        ret_gt, frame_gt = gt_cap.read()\n",
    "        if ret_pred and ret_gt:\n",
    "            # mini-map resizes to width M while maintaining aspect ratio\n",
    "            frame_pred_resized = cv2.resize(frame_pred, (int(M), int(H)), interpolation=cv2.INTER_LINEAR)\n",
    "            frame_gt_resized   = cv2.resize(frame_gt,   (int(M), int(H)), interpolation=cv2.INTER_LINEAR)\n",
    "            alpha = 0.8  # Semi-transparent composite rate\n",
    "            \n",
    "            # Predictionを main_frame 上の位置へ配置：位置は x=pred_x, y=overlay_y\n",
    "            roi_pred = main_frame[overlay_y:overlay_y+int(H), pred_x:pred_x+int(M)]\n",
    "            # The sizes should match, so they are combined as they are\n",
    "            blended_pred = cv2.addWeighted(roi_pred, 1 - alpha, frame_pred_resized, alpha, 0)\n",
    "            main_frame[overlay_y:overlay_y+int(H), pred_x:pred_x+int(M)] = blended_pred\n",
    "            \n",
    "            # Ground Truth Placement\n",
    "            roi_gt = main_frame[overlay_y:overlay_y+int(H), gt_x:gt_x+int(M)]\n",
    "            blended_gt = cv2.addWeighted(roi_gt, 1 - alpha, frame_gt_resized, alpha, 0)\n",
    "            main_frame[overlay_y:overlay_y+int(H), gt_x:gt_x+int(M)] = blended_gt\n",
    "            \n",
    "            # --- Label Drawing ---\n",
    "            # Labels are placed in black letters at the bottom of the mini-map. The x coordinate of the label is in the center of each mini-map.\n",
    "            pred_label_x = pred_x + int(M/2)\n",
    "            gt_label_x = gt_x + int(M/2)\n",
    "            label_y = overlay_y + int(H) + 25  \n",
    "            cv2.putText(main_frame, \"Prediction\", (pred_label_x - 75, label_y), font, font_scale, label_color, font_thickness)\n",
    "            cv2.putText(main_frame, \"Ground Truth\", (gt_label_x - 100, label_y), font, font_scale, label_color, font_thickness)\n",
    "            \n",
    "        out.write(main_frame)\n",
    "        frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "    pred_cap.release()\n",
    "    gt_cap.release()\n",
    "    out.release()\n",
    "    print(f\"{video_file} processing is complete. Output: {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
