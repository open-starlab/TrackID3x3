{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homography Matrix:\n",
      " [[ 1.00270933e+00 -8.80391018e+00  2.53903005e+03]\n",
      " [-1.93944985e+00 -8.91569008e+00  4.07722989e+03]\n",
      " [-1.58145426e-04 -5.04286435e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import ndjson\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FFMpegWriter\n",
    "\n",
    "\n",
    "# Read NDJSON file with keypoints recorded by Labelbox\n",
    "ndjson_file = \"../../ground_truth/Indoor/court_keypoints/Indoor.ndjson\"  # NDJSON file path\n",
    "with open(ndjson_file, \"r\") as f:\n",
    "    data = ndjson.load(f)\n",
    "\n",
    "# Key point names and corresponding court coordinate system coordinates\n",
    "keypoint_mapping = {\n",
    "    \"key_1_tokoha\": [0, 0],         \n",
    "    \"key_6_tokoha\": [0, 1505],      \n",
    "    \"key_9_tokoha\": [950, 0],       \n",
    "    \"key_12_tokoha\": [950, 1505]    \n",
    "}\n",
    "\n",
    "# Extract key point coordinates on the image from NDJSON\n",
    "points_image = []\n",
    "points_court = []\n",
    "\n",
    "annotations = data[0][\"projects\"][\"clqqo8sg92kjv07yx56yad247\"][\"labels\"][0][\"annotations\"][\"objects\"]\n",
    "for annotation in annotations:\n",
    "    key_name = annotation[\"value\"]\n",
    "    if key_name in keypoint_mapping:\n",
    "        x, y = annotation[\"point\"][\"x\"], annotation[\"point\"][\"y\"]\n",
    "        points_image.append([x, y])\n",
    "        points_court.append(keypoint_mapping[key_name]) \n",
    "\n",
    "# Convert to numpy array\n",
    "points_image = np.array(points_image, dtype=np.float32)\n",
    "points_court = np.array(points_court, dtype=np.float32)\n",
    "\n",
    "# Calculate homography matrix\n",
    "H, status = cv2.findHomography(points_image, points_court)\n",
    "\n",
    "print(\"Homography Matrix:\\n\", H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homographic_transformation(x, y, H):\n",
    "    \"\"\"Transform the coordinates on the image into the Court coordinate system by homographic transformation\"\"\"\n",
    "    point = np.array([x, y, 1.0]).reshape(3, 1)  # Extended for homographic conversion\n",
    "    transformed_point = np.dot(H, point)\n",
    "    transformed_point /= transformed_point[2]  # Normalization\n",
    "    return transformed_point[0][0], transformed_point[1][0]  # (x', y')\n",
    "\n",
    "# Court range (using keypoint_mapping)\n",
    "min_x, min_y = keypoint_mapping[\"key_1_tokoha\"]\n",
    "max_x, max_y = keypoint_mapping[\"key_12_tokoha\"]\n",
    "max_x += 100  # give someone ample space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S6T2_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S6T2_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S6T2_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S6T3_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S6T3_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S6T3_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S6T4_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S6T4_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S6T4_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S6T5_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S6T5_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S6T5_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S6T6_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S6T6_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S6T6_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S6T7_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S6T7_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S6T7_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S1T1_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S1T1_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S1T1_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S1T2_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S1T2_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S1T2_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S1T3_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S1T3_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S1T3_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S1T4_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S1T4_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S1T4_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S1T5_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S1T5_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S1T5_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S1T6_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S1T6_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S1T6_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S1T7_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S1T7_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S1T7_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S2T1_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S2T1_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S2T1_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S2T2_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S2T2_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S2T2_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S2T3_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S2T3_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S2T3_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S2T4_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S2T4_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S2T4_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S2T5_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S2T5_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S2T5_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S2T6_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S2T6_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S2T6_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S2T7_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S2T7_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S2T7_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S3T1_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S3T1_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S3T1_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S3T2_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S3T2_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S3T2_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S3T3_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S3T3_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S3T3_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S3T4_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S3T4_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S3T4_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S3T5_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S3T5_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S3T5_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S3T6_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S3T6_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S3T6_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S3T7_pre.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S3T7_pre.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S3T7_pre.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S4T1_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S4T1_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S4T1_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S4T2_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S4T2_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S4T2_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S4T3_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S4T3_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S4T3_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S4T4_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S4T4_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S4T4_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S4T5_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S4T5_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S4T5_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S4T6_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S4T6_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S4T6_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S4T7_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S4T7_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S4T7_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S5T1_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S5T1_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S5T1_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S5T2_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S5T2_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S5T2_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S5T3_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S5T3_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S5T3_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S5T4_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S5T4_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S5T4_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S5T5_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S5T5_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S5T5_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S5T6_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S5T6_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S5T6_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S5T7_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S5T7_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S5T7_post.txt\n",
      "Processed: ../BoT-SORT_outputs/Indoor/basket_S6T1_post.txt -> ../BoT-SORT_outputs/Indoor/transformed/basket_S6T1_post.txt, ../BoT-SORT_outputs/Indoor/filtered/basket_S6T1_post.txt\n",
      "Convert all MOT files, saved in ../BoT-SORT_outputs/Indoor/transformed/ (court coordinates) and ../BoT-SORT_outputs/Indoor/filtered/ (bboxes data).\n"
     ]
    }
   ],
   "source": [
    "# Input folder (BoT-SORT output)\n",
    "input_dir = \"../../BoT-SORT_outputs/Indoor\"\n",
    "\n",
    "# Output folder (court coordinate data)\n",
    "output_dir_court = \"../../BoT-SORT_outputs/Indoor/transformed/\"\n",
    "os.makedirs(output_dir_court, exist_ok=True)\n",
    "\n",
    "# Output folder (filtered bbox data)\n",
    "output_dir_bbox = \"../../BoT-SORT_outputs/Indoor/filtered/\"\n",
    "os.makedirs(output_dir_bbox, exist_ok=True)\n",
    "\n",
    "# Get MOT files\n",
    "mot_files = glob.glob(os.path.join(input_dir, \"*.txt\"))\n",
    "\n",
    "\n",
    "for mot_file in mot_files:\n",
    "    \n",
    "    # Read MOT files\n",
    "    df = pd.read_csv(\n",
    "        mot_file,\n",
    "        header=None,\n",
    "        names=[\"frame_id\", \"id\", \"x\", \"y\", \"width\", \"height\", \"conf\", \"class\", \"visibility\", \"empty\"],\n",
    "        sep=\",\",\n",
    "    )\n",
    "\n",
    "    # Calculate the midpoint of the bottom edge of bbox\n",
    "    df[\"bottom_center_x\"] = df[\"x\"] + df[\"width\"] / 2\n",
    "    df[\"bottom_center_y\"] = df[\"y\"] + df[\"height\"]\n",
    "\n",
    "    # Homography transformation of the midpoint of the lower edge of each bbox\n",
    "    transformed_coords = df.apply(\n",
    "        lambda row: homographic_transformation(row[\"bottom_center_x\"], row[\"bottom_center_y\"], H),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Save the transformed coordinates in a new column\n",
    "    df[\"court_x\"] = transformed_coords.map(lambda coord: coord[0])\n",
    "    df[\"court_y\"] = transformed_coords.map(lambda coord: coord[1])\n",
    "\n",
    "    # Delete bbox outside of court range\n",
    "    df_court = df[(df[\"court_x\"] >= min_x) & (df[\"court_x\"] <= max_x) & \n",
    "                  (df[\"court_y\"] >= min_y) & (df[\"court_y\"] <= max_y)].copy()\n",
    "    \n",
    "    # Filter rows for each frame with 7 or more bounding boxes\n",
    "    df_filtered = df_court.groupby(\"frame_id\").filter(lambda group: len(group) >= 7)\n",
    "\n",
    "    # Process each frame with 7 or more bounding boxes\n",
    "    for frame_id, group in df_filtered.groupby(\"frame_id\"):\n",
    "        # Sort by the x coordinate (court_x) and select the top 6\n",
    "        sorted_group = group.sort_values(by=\"court_x\", ascending=False).iloc[:6]\n",
    "\n",
    "        # Replace the original group with the sorted and limited group\n",
    "        df_court.loc[df_court[\"frame_id\"] == frame_id, :] = sorted_group\n",
    "    \n",
    "    df_court = df_court.dropna() \n",
    "    \n",
    "    df_court[\"frame_id\"] = df_court[\"frame_id\"].astype(int) # Convert to integer\n",
    "    df_court[\"id\"] = df_court[\"id\"].astype(int) # Convert to integer\n",
    "    \n",
    "    # bbox data in original MOT format\n",
    "    df_bbox = df_court[[\"frame_id\", \"id\", \"x\", \"y\", \"width\", \"height\", \"conf\", \"class\", \"visibility\", \"empty\"]]\n",
    "\n",
    "    # Data of court coordinates (bbox coordinates are deleted and court coordinates are retained)\n",
    "    df_court = df_court[[\"frame_id\", \"id\", \"court_x\", \"court_y\"]]\n",
    "\n",
    "    # keep relative paths of files\n",
    "    relative_path = os.path.relpath(mot_file, input_dir)\n",
    "    \n",
    "    # Save converted MOT data (court coordinates)\n",
    "    output_file_court = os.path.join(output_dir_court, relative_path)\n",
    "    os.makedirs(os.path.dirname(output_file_court), exist_ok=True)\n",
    "    df_court.to_csv(output_file_court, index=False, header=None, sep=\",\")  # Save in MOT format\n",
    "\n",
    "    # Save converted MOT data (original bbox format)\n",
    "    output_file_bbox = os.path.join(output_dir_bbox, relative_path)\n",
    "    os.makedirs(os.path.dirname(output_file_bbox), exist_ok=True)\n",
    "    df_bbox.to_csv(output_file_bbox, index=False, header=None, sep=\",\")  # Save in MOT format\n",
    "\n",
    "    print(f\"Processed: {mot_file} -> {output_file_court}, {output_file_bbox}\")\n",
    "\n",
    "print(f\"Convert all MOT files, saved in {output_dir_court} (court coordinates) and {output_dir_bbox} (bboxes data).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
