{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a9daa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP4動画を保存しました: annotated_video_frames_951-1000.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import imageio\n",
    "import numpy as np\n",
    "import re\n",
    "import colorsys\n",
    "from collections import defaultdict\n",
    "\n",
    "# ===== 改良版：各キーに対してより識別しやすい色を生成する =====\n",
    "# グローバル変数でキーごとの色マッピングと次に使う色相を保持\n",
    "_key_color_map = {}\n",
    "_GOLDEN_RATIO_CONJUGATE = 0.618033988749895\n",
    "_next_hue = 0.0\n",
    "\n",
    "def get_color(key):\n",
    "    \"\"\"\n",
    "    Golden ratio を用いて次々に異なる色相 (Hue) を生成し、\n",
    "    各キーに一意の色を割り当てる。\n",
    "    昨今のハッシュ法による画一的な色だけでなく、色相環上で均等に離れた色を生成できる。\n",
    "    戻り値は OpenCV 用の BGR (0-255) タプル。\n",
    "    \"\"\"\n",
    "    global _next_hue\n",
    "    # まだ割り当てられていないキーなら、新色を生成してマッピング\n",
    "    if key not in _key_color_map:\n",
    "        # ゴールデンレシオ共役を加算して色相を決定\n",
    "        hue = (_next_hue + _GOLDEN_RATIO_CONJUGATE) % 1.0\n",
    "        _next_hue = hue\n",
    "        s, v = 0.8, 0.9\n",
    "        r, g, b = colorsys.hsv_to_rgb(hue, s, v)\n",
    "        # BGR形式に変換して保存\n",
    "        _key_color_map[key] = (int(b * 255), int(g * 255), int(r * 255))\n",
    "    return _key_color_map[key]\n",
    "\n",
    "# ========== ② 各種パスと対象フレーム範囲 ==========\n",
    "# 対象動画ファイル（この動画は最初から始まるのでオフセット不要）\n",
    "video_path = os.path.join(\"../../videos\", \"Drone\", \"1_1_6000.mp4\")\n",
    "\n",
    "# JSON（姿勢キーポイント）ファイルのディレクトリ\n",
    "pose_dir = os.path.join(\"../../ground_truth\", \"Drone\", \"pose\")\n",
    "\n",
    "# MOT形式のbboxファイルのパス（MOT形式：各行 \"frame id x y width height ...\" を想定）\n",
    "bbox_file_path = os.path.join(\"../../ground_truth\", \"Drone\", \"40_1215_gt.txt\")\n",
    "\n",
    "# 対象フレーム番号（動画とJSON, MOTが同じ番号付けになっていると仮定）\n",
    "target_frame_start = 951\n",
    "target_frame_end   = 1000\n",
    "\n",
    "# bboxのタイミングがずれている場合のオフセット補正（今回は逆にずれているので、MOT情報が後ろの場合）\n",
    "# ここでは「bbox_offset = 50」として、現在のフレーム番号から50フレーム引いた番号のbboxを使用する\n",
    "bbox_offset = 40\n",
    "\n",
    "# ========== ③ MOT形式のbboxファイルの読み込み ==========\n",
    "# bbox_lines_frame: キー＝フレーム番号, 値＝該当フレームの検出リスト（各検出は (id, x, y, width, height)）\n",
    "bbox_lines_frame = defaultdict(list)\n",
    "if os.path.exists(bbox_file_path):\n",
    "    with open(bbox_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 6:\n",
    "                continue\n",
    "            try:\n",
    "                frame_no = int(parts[0])\n",
    "                det_id   = int(parts[1])\n",
    "                x = float(parts[2])\n",
    "                y = float(parts[3])\n",
    "                width  = float(parts[4])\n",
    "                height = float(parts[5])\n",
    "                bbox_lines_frame[frame_no].append((det_id, x, y, width, height))\n",
    "            except Exception as e:\n",
    "                print(\"bbox parse error:\", e)\n",
    "else:\n",
    "    print(\"bboxファイルが見つかりません:\", bbox_file_path)\n",
    "\n",
    "# ========== ④ 動画ファイルの準備 ==========\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(f\"動画ファイル {video_path} を開けません。\")\n",
    "\n",
    "# 対象フレームは番号951～1000（動画内のフレーム番号と対応）\n",
    "current_frame = 0\n",
    "annotated_frames = []\n",
    "\n",
    "# ========== ⑤ 各フレームごとの処理 ==========\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    current_frame += 1\n",
    "    if current_frame < target_frame_start or current_frame > target_frame_end:\n",
    "        continue\n",
    "\n",
    "    # 対応するJSONファイル（例：\"frame_951.json\"）を読み込む\n",
    "    json_filename = f\"frame_{current_frame}.json\"\n",
    "    json_path = os.path.join(pose_dir, json_filename)\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"JSONファイルが見つかりません: {json_path}\")\n",
    "        continue\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # (A) 各キーごとにそのフレームの姿勢キーポイント群の重心を計算\n",
    "    key_centroids = {}\n",
    "    annotations = data.get(\"annotations\", {})\n",
    "    for key, points in annotations.items():\n",
    "        pts_arr = np.array(points)\n",
    "        if pts_arr.size == 0:\n",
    "            continue\n",
    "        centroid = np.mean(pts_arr, axis=0)\n",
    "        key_centroids[key] = centroid\n",
    "\n",
    "    # (B) 当該フレームにおけるMOT検出（bbox）の取得（オフセット補正：現在のフレーム番号から50を引く）\n",
    "    available_dets = []\n",
    "    corrected_frame = current_frame - bbox_offset\n",
    "    if corrected_frame in bbox_lines_frame:\n",
    "        for det in bbox_lines_frame[corrected_frame]:\n",
    "            # 各検出の中心座標 (x + width/2, y + height/2)\n",
    "            _, x, y, width, height = det\n",
    "            center = np.array([x + width/2, y + height/2])\n",
    "            available_dets.append({'det': det, 'center': center})\n",
    "    else:\n",
    "        available_dets = []\n",
    "    \n",
    "    # (C) 各キーごとに、未割当の検出から重心との距離が最小のものをグリーディーに割当\n",
    "    key_to_bbox = {}\n",
    "    for key, cent in key_centroids.items():\n",
    "        best_idx = -1\n",
    "        best_dist = float('inf')\n",
    "        for idx, det_info in enumerate(available_dets):\n",
    "            d = np.linalg.norm(cent - det_info['center'])\n",
    "            if d < best_dist:\n",
    "                best_dist = d\n",
    "                best_idx = idx\n",
    "        if best_idx != -1:\n",
    "            key_to_bbox[key] = available_dets[best_idx]['det']\n",
    "            available_dets.pop(best_idx)\n",
    "    \n",
    "    # (D) 描画: キーポイントを円で描画（線は結ばない）\n",
    "    for key, points in annotations.items():\n",
    "        color = get_color(key)\n",
    "        radius = 8\n",
    "        for p in points:\n",
    "            pt = (int(round(p[0])), int(round(p[1])))\n",
    "            cv2.circle(frame, pt, radius, color, thickness=-1)\n",
    "    \n",
    "    # (E) 描画: 対応付けたbboxをキーごとの色で矩形描画\n",
    "    for key, det in key_to_bbox.items():\n",
    "        _, x, y, width, height = det\n",
    "        top_left = (int(round(x)), int(round(y)))\n",
    "        bottom_right = (int(round(x + width)), int(round(y + height)))\n",
    "        color = get_color(key)\n",
    "        cv2.rectangle(frame, top_left, bottom_right, color, thickness=2)\n",
    "\n",
    "    # (F) フレームをRGB形式に変換してリストに追加\n",
    "    annotated_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    annotated_frames.append(annotated_frame)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# ========== ⑥ GIFおよびMP4の出力 ==========\n",
    "if annotated_frames:\n",
    "    fps = 20  # フレームレート（調整可能）\n",
    "\n",
    "    # GIF出力\n",
    "    # gif_out_path = 'annotated_animation_frames_951-1000.gif'\n",
    "    # imageio.mimsave(gif_out_path, annotated_frames, fps=fps)\n",
    "    # print(f\"GIF画像を保存しました: {gif_out_path}\")\n",
    "\n",
    "    # MP4出力\n",
    "    height, width, _ = annotated_frames[0].shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_out_path = 'annotated_video_frames_951-1000.mp4'\n",
    "    video_writer = cv2.VideoWriter(video_out_path, fourcc, fps, (width, height))\n",
    "    for frame in annotated_frames:\n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        video_writer.write(frame_bgr)\n",
    "    video_writer.release()\n",
    "    print(f\"MP4動画を保存しました: {video_out_path}\")\n",
    "else:\n",
    "    print(\"対象フレームがないか、画像の読み込みに失敗しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f9522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
